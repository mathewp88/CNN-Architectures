{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. AlexNet","metadata":{"id":"DOV-7BbZAHFv"}},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{"id":"XvJ9ZkdyALzW"}},{"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import datasets\nfrom torchvision import transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom tqdm import tqdm\nfrom torch.utils.tensorboard import SummaryWriter\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Device Setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"AlNF5q7bALPf","execution":{"iopub.status.busy":"2023-06-22T06:55:08.587005Z","iopub.execute_input":"2023-06-22T06:55:08.587382Z","iopub.status.idle":"2023-06-22T06:55:08.597495Z","shell.execute_reply.started":"2023-06-22T06:55:08.587349Z","shell.execute_reply":"2023-06-22T06:55:08.596363Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Loading the CIFAR-10 Dataset","metadata":{"id":"82m49XTyCKl2"}},{"cell_type":"code","source":"def load_train_val( data_dir,\n                    batch_size,\n                    random_seed,\n                    augment,\n                    val_size=0.1,\n                    shuffle=True):\n\n  normalize = transforms.Normalize(\n        mean=[0.4913997551666284, 0.48215855929893703, 0.4465309133731618],\n        std=[0.24703225141799082, 0.24348516474564, 0.26158783926049628],\n  )\n\n  # Transform\n  transform = transforms.Compose([\n      transforms.Resize((227,227)),\n      transforms.ToTensor(),\n      normalize,\n  ])\n\n  if augment:\n    train_transform = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        normalize,\n    ])\n  else:\n    train_transform = transforms.Compose([\n        transforms.Resize((227,227)),\n        transforms.ToTensor(),\n        normalize,\n    ])\n\n\n  # load the dataset\n  train_dataset = datasets.CIFAR10(\n      root=data_dir, train=True,\n      download=True, transform=train_transform,\n  )\n\n  val_dataset = datasets.CIFAR10(\n      root=data_dir, train=True,\n      download=True, transform=transform,\n  )\n\n  num_train = len(train_dataset)\n  indices = list(range(num_train))\n  split = int(np.floor(val_size * num_train))\n  if shuffle:\n      np.random.seed(random_seed)\n      np.random.shuffle(indices)\n\n  train_idx, val_idx = indices[split:], indices[:split]\n  train_sampler = SubsetRandomSampler(train_idx)\n  val_sampler = SubsetRandomSampler(val_idx)\n\n  train_loader = torch.utils.data.DataLoader(\n      train_dataset, batch_size=batch_size, sampler=train_sampler)\n\n  val_loader = torch.utils.data.DataLoader(\n      val_dataset, batch_size=batch_size, sampler=val_sampler)\n\n  return (train_loader, val_loader)\n\ndef load_test(data_dir,\n              batch_size,\n              shuffle=True):\n\n  normalize = transforms.Normalize(\n        mean=[0.4913997551666284, 0.48215855929893703, 0.4465309133731618],\n        std=[0.24703225141799082, 0.24348516474564, 0.26158783926049628],\n  )\n\n  # Transform\n  transform = transforms.Compose([\n      transforms.Resize((227,227)),\n      transforms.ToTensor(),\n      normalize,\n  ])\n\n  # load the dataset\n  test_dataset = datasets.CIFAR10(\n      root=data_dir, train=True,\n      download=True, transform=transform,\n  )\n\n  data_loader = torch.utils.data.DataLoader(\n      test_dataset, batch_size=batch_size, shuffle=shuffle\n  )\n\n  return data_loader","metadata":{"id":"QzxWpA6iCRoH","execution":{"iopub.status.busy":"2023-06-22T06:55:08.599449Z","iopub.execute_input":"2023-06-22T06:55:08.599905Z","iopub.status.idle":"2023-06-22T06:55:08.615841Z","shell.execute_reply.started":"2023-06-22T06:55:08.599872Z","shell.execute_reply":"2023-06-22T06:55:08.614945Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_loader, val_loader = load_train_val(data_dir = './data', batch_size = 128, augment=False, random_seed = 1)\ntest_loader = load_test(data_dir = './data', batch_size = 128)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5C7WiBPbHUho","outputId":"ad4b3301-98ba-45b2-80de-1e7c477dbcb4","execution":{"iopub.status.busy":"2023-06-22T06:55:08.617840Z","iopub.execute_input":"2023-06-22T06:55:08.618426Z","iopub.status.idle":"2023-06-22T06:55:11.285507Z","shell.execute_reply.started":"2023-06-22T06:55:08.618375Z","shell.execute_reply":"2023-06-22T06:55:11.284557Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## AlexNet Model","metadata":{"id":"rxOB-DSfK6ro"}},{"cell_type":"code","source":"class AlexNet(nn.Module):\n  def __init__(self, num_classes=10):\n    super(AlexNet, self).__init__()\n    self.l1 = nn.Sequential(\n      nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n      nn.BatchNorm2d(96),\n      nn.ReLU(),\n      nn.MaxPool2d(kernel_size = 3, stride = 2))\n    self.l2 = nn.Sequential(\n      nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n      nn.BatchNorm2d(256),\n      nn.ReLU(),\n      nn.MaxPool2d(kernel_size = 3, stride = 2))\n    self.l3 = nn.Sequential(\n      nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n      nn.BatchNorm2d(384),\n      nn.ReLU())\n    self.l4 = nn.Sequential(\n      nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n      nn.BatchNorm2d(384),\n      nn.ReLU())\n    self.l5 = nn.Sequential(\n      nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n      nn.BatchNorm2d(256),\n      nn.ReLU(),\n      nn.MaxPool2d(kernel_size = 3, stride = 2))\n    self.fc = nn.Sequential(\n      nn.Dropout(0.5),\n      nn.Linear(9216, 4096),\n      nn.ReLU())\n    self.fc1 = nn.Sequential(\n      nn.Dropout(0.5),\n      nn.Linear(4096, 4096),\n      nn.ReLU())\n    self.fc2= nn.Sequential(\n      nn.Linear(4096, num_classes))\n\n  def forward(self, x):\n    out = self.l1(x)\n    out = self.l2(out)\n    out = self.l3(out)\n    out = self.l4(out)\n    out = self.l5(out)\n    out = out.reshape(out.size(0), -1)\n    out = self.fc(out)\n    out = self.fc1(out)\n    out = self.fc2(out)\n    return out","metadata":{"id":"nkOV_LsyK_bA","execution":{"iopub.status.busy":"2023-06-22T06:55:11.287063Z","iopub.execute_input":"2023-06-22T06:55:11.287482Z","iopub.status.idle":"2023-06-22T06:55:11.300046Z","shell.execute_reply.started":"2023-06-22T06:55:11.287448Z","shell.execute_reply":"2023-06-22T06:55:11.298909Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Set HyperParams","metadata":{"id":"oM4jqK9RM15B"}},{"cell_type":"code","source":"num_classes = 10\nnum_epochs = 100\nbatch_size = 128\nlearning_rate = 0.005\n\n# constant for classes\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n\n# Adding weights using normal distribution\ndef init_weights(model):\n  if (isinstance(model, nn.Conv2d) or isinstance(model, nn.Linear)):\n    model.weight.data.normal_(0, 0.01)\n    model.bias.data.fill_(0.)\n\nmodel = AlexNet(num_classes).to(device)\nmodel.apply(init_weights)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)\n\n# Training length\ntotal_step = len(train_loader)\n\n#Tensorboard Setup\ntb = SummaryWriter(\"runs/AlexNet\")\nimages, labels = next(iter(train_loader))\ngrid = torchvision.utils.make_grid(images)\ntb.add_image(\"images\", grid)","metadata":{"id":"l70s93JIN9Dw","execution":{"iopub.status.busy":"2023-06-22T06:55:11.302693Z","iopub.execute_input":"2023-06-22T06:55:11.303177Z","iopub.status.idle":"2023-06-22T06:55:13.760195Z","shell.execute_reply.started":"2023-06-22T06:55:11.303146Z","shell.execute_reply":"2023-06-22T06:55:13.738818Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{"id":"5gys9JHJcnU1"}},{"cell_type":"code","source":"total_steps = len(train_loader)\n\nfor epoch in tqdm(range(num_epochs)):\n    for i, (images, labels) in enumerate(train_loader):\n        # Move tensors to the configured device\n        images = images.to(device)\n        labels = labels.to(device)\n\n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    #if (epoch+1) % 10 == 0:\n    #  print (f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_steps}], Loss: {loss.item():.4f}\")\\\n    \n    y_pred = [] # save predction\n    y_true = [] # save ground truth\n    # Validation\n    with torch.no_grad():\n        correct = 0\n        total = 0\n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            y_pred.extend(predicted.data.cpu().numpy())\n            y_true.extend(labels.data.cpu().numpy())\n            del images, labels, outputs\n        #if(epoch+1) % 10 == 0:\n        #  print(f\"Accuracy of the network on the {5000} validation images: {100*correct/total} %\")\n    tb.add_scalar(\"Loss\", loss, epoch)\n    tb.add_scalar(\"Correct\", correct, epoch)\n    tb.add_scalar(\"Accuracy\", correct/total, epoch)\n    # Build confusion matrix\n    cf_matrix = confusion_matrix(y_true, y_pred)\n    df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index=[i for i in classes],\n                         columns=[i for i in classes])\n    plt.figure(figsize=(12, 7)) \n    tb.add_figure(\"Confusion matrix\", sn.heatmap(df_cm, annot=True).get_figure(), epoch)\n    for name, weight in model.named_parameters():\n      tb.add_histogram(name,weight, epoch)\n      tb.add_histogram(f'{name}.grad',weight.grad, epoch)","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"i3xlHEEWcmTO","outputId":"ae179036-4794-459a-cfa0-142405ccceb8","execution":{"iopub.status.busy":"2023-06-22T06:55:13.766630Z","iopub.execute_input":"2023-06-22T06:55:13.766967Z","iopub.status.idle":"2023-06-22T10:10:26.230928Z","shell.execute_reply.started":"2023-06-22T06:55:13.766925Z","shell.execute_reply":"2023-06-22T10:10:26.225375Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"100%|██████████| 100/100 [3:15:12<00:00, 117.12s/it] \n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Testing","metadata":{"id":"JS8Y8m_cdEC4"}},{"cell_type":"code","source":"with torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in tqdm(test_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        del images, labels, outputs\n    print(f\"Accuracy of the network on the {10000} test images: {100*correct/total} %\")","metadata":{"id":"8jhKBsa4dFfA","execution":{"iopub.status.busy":"2023-06-22T10:10:26.232791Z","iopub.execute_input":"2023-06-22T10:10:26.233236Z","iopub.status.idle":"2023-06-22T10:12:22.229544Z","shell.execute_reply.started":"2023-06-22T10:10:26.233194Z","shell.execute_reply":"2023-06-22T10:12:22.228380Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"100%|██████████| 391/391 [01:55<00:00,  3.37it/s]","output_type":"stream"},{"name":"stdout","text":"Accuracy of the network on the 10000 test images: 97.486 %\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Tensorboard","metadata":{"id":"6TJjsQKk1PAS"}},{"cell_type":"code","source":"tb.flush()\ntb.close()\n%load_ext tensorboard\n%tensorboard --logdir=runs/AlexNet","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}