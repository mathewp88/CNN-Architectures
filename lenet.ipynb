{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LeNET","metadata":{"id":"DOV-7BbZAHFv"}},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{"id":"XvJ9ZkdyALzW"}},{"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import datasets\nfrom torchvision import transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom tqdm import tqdm\nfrom torch.utils.tensorboard import SummaryWriter\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Device Setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"AlNF5q7bALPf","execution":{"iopub.status.busy":"2023-06-22T17:37:33.153611Z","iopub.execute_input":"2023-06-22T17:37:33.154233Z","iopub.status.idle":"2023-06-22T17:37:33.161973Z","shell.execute_reply.started":"2023-06-22T17:37:33.154199Z","shell.execute_reply":"2023-06-22T17:37:33.161061Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Loading the MNIST Dataset","metadata":{"id":"82m49XTyCKl2"}},{"cell_type":"code","source":"batch_size = 64\nval_size = 0.1\n\ntrain_dataset = torchvision.datasets.MNIST(root = './data',\n                                           train = True,\n                                           transform = transforms.Compose([\n                                                  transforms.Resize((32,32)),\n                                                  transforms.ToTensor(),\n                                                  transforms.Normalize(mean = (0.1307,), std = (0.3081,))]),\n                                           download = True)\n\nval_dataset = torchvision.datasets.MNIST(root = './data',\n                                           train = True,\n                                           transform = transforms.Compose([\n                                                  transforms.Resize((32,32)),\n                                                  transforms.ToTensor(),\n                                                  transforms.Normalize(mean = (0.1307,), std = (0.3081,))]),\n                                           download = True)\n\ntest_dataset = torchvision.datasets.MNIST(root = './data',\n                                          train = False,\n                                          transform = transforms.Compose([\n                                                  transforms.Resize((32,32)),\n                                                  transforms.ToTensor(),\n                                                  transforms.Normalize(mean = (0.1325,), std = (0.3105,))]),\n                                          download=True)\n\nnum_train = len(train_dataset)\nindices = list(range(num_train))\nsplit = int(np.floor(val_size * num_train))\ntrain_idx, val_idx = indices[split:], indices[:split]\ntrain_sampler = SubsetRandomSampler(train_idx)\nval_sampler = SubsetRandomSampler(val_idx)\n\n\ntrain_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n                                           batch_size = batch_size,\n                                           sampler = train_sampler)\n\nval_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n                                           batch_size = batch_size,\n                                           sampler = val_sampler)\n\ntest_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n                                           batch_size = batch_size,\n                                           shuffle = True)","metadata":{"id":"QzxWpA6iCRoH","execution":{"iopub.status.busy":"2023-06-22T17:37:33.163809Z","iopub.execute_input":"2023-06-22T17:37:33.164227Z","iopub.status.idle":"2023-06-22T17:37:33.346865Z","shell.execute_reply.started":"2023-06-22T17:37:33.164199Z","shell.execute_reply":"2023-06-22T17:37:33.345728Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## LeNET5 Model","metadata":{"id":"rxOB-DSfK6ro"}},{"cell_type":"code","source":"class LeNet5(nn.Module):\n    def __init__(self, num_classes):\n        super(LeNet5, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n            nn.BatchNorm2d(6),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.fc = nn.Linear(400, 120)\n        self.relu = nn.ReLU()\n        self.fc1 = nn.Linear(120, 84)\n        self.relu1 = nn.ReLU()\n        self.fc2 = nn.Linear(84, num_classes)\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = out.reshape(out.size(0), -1)\n        out = self.fc(out)\n        out = self.relu(out)\n        out = self.fc1(out)\n        out = self.relu1(out)\n        out = self.fc2(out)\n        return out","metadata":{"id":"nkOV_LsyK_bA","execution":{"iopub.status.busy":"2023-06-22T17:37:33.348732Z","iopub.execute_input":"2023-06-22T17:37:33.349069Z","iopub.status.idle":"2023-06-22T17:37:33.357687Z","shell.execute_reply.started":"2023-06-22T17:37:33.349041Z","shell.execute_reply":"2023-06-22T17:37:33.356560Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Set HyperParams","metadata":{"id":"oM4jqK9RM15B"}},{"cell_type":"code","source":"num_classes = 10\nnum_epochs = 100\nbatch_size = 64\nlearning_rate = 0.01\n\n# constant for classes\nclasses = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n\n\n# Adding weights using normal distribution\ndef init_weights(model):\n  if (isinstance(model, nn.Conv2d) or isinstance(model, nn.Linear)):\n    model.weight.data.normal_(0, 0.01)\n    model.bias.data.fill_(0.)\n\nmodel = LeNet5(num_classes).to(device)\nmodel.apply(init_weights)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)\n\n# Training length\ntotal_step = len(train_loader)\n\n#Tensorboard Setup\ntb = SummaryWriter(\"runs/LeNET\")\nimages, labels = next(iter(train_loader))\ngrid = torchvision.utils.make_grid(images)\ntb.add_image(\"images\", grid)","metadata":{"id":"l70s93JIN9Dw","execution":{"iopub.status.busy":"2023-06-22T17:37:33.359267Z","iopub.execute_input":"2023-06-22T17:37:33.359552Z","iopub.status.idle":"2023-06-22T17:37:33.478538Z","shell.execute_reply.started":"2023-06-22T17:37:33.359527Z","shell.execute_reply":"2023-06-22T17:37:33.477611Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{"id":"5gys9JHJcnU1"}},{"cell_type":"code","source":"total_steps = len(train_loader)\n\nfor epoch in tqdm(range(num_epochs)):\n    for i, (images, labels) in enumerate(train_loader):\n        # Move tensors to the configured device\n        images = images.to(device)\n        labels = labels.to(device)\n\n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    #if (epoch+1) % 10 == 0:\n    #  print (f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_steps}], Loss: {loss.item():.4f}\")\\\n    \n    y_pred = [] # save predction\n    y_true = [] # save ground truth\n    # Validation\n    with torch.no_grad():\n        correct = 0\n        total = 0\n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            y_pred.extend(predicted.data.cpu().numpy())\n            y_true.extend(labels.data.cpu().numpy())\n            del images, labels, outputs\n        #if(epoch+1) % 10 == 0:\n        #  print(f\"Accuracy of the network on the {5000} validation images: {100*correct/total} %\")\n    tb.add_scalar(\"Loss\", loss, epoch)\n    tb.add_scalar(\"Correct\", correct, epoch)\n    tb.add_scalar(\"Accuracy\", correct/total, epoch)\n    # Build confusion matrix\n    cf_matrix = confusion_matrix(y_true, y_pred)\n    df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index=[i for i in classes],\n                         columns=[i for i in classes])\n    plt.figure(figsize=(12, 7)) \n    tb.add_figure(\"Confusion matrix\", sn.heatmap(df_cm, annot=True).get_figure(), epoch)\n    for name, weight in model.named_parameters():\n      tb.add_histogram(name,weight, epoch)\n      tb.add_histogram(f'{name}.grad',weight.grad, epoch)","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"i3xlHEEWcmTO","outputId":"ae179036-4794-459a-cfa0-142405ccceb8","execution":{"iopub.status.busy":"2023-06-22T17:37:33.481216Z","iopub.execute_input":"2023-06-22T17:37:33.481624Z","iopub.status.idle":"2023-06-22T18:16:37.019884Z","shell.execute_reply.started":"2023-06-22T17:37:33.481584Z","shell.execute_reply":"2023-06-22T18:16:37.018774Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"100%|██████████| 100/100 [39:03<00:00, 23.44s/it]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Testing","metadata":{"id":"JS8Y8m_cdEC4"}},{"cell_type":"code","source":"with torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in tqdm(test_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        del images, labels, outputs\n    print(f\"Accuracy of the network on the {10000} test images: {100*correct/total} %\")","metadata":{"id":"8jhKBsa4dFfA","execution":{"iopub.status.busy":"2023-06-22T18:16:37.021148Z","iopub.execute_input":"2023-06-22T18:16:37.022413Z","iopub.status.idle":"2023-06-22T18:16:40.107651Z","shell.execute_reply.started":"2023-06-22T18:16:37.022367Z","shell.execute_reply":"2023-06-22T18:16:40.106599Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"100%|██████████| 157/157 [00:03<00:00, 51.22it/s]","output_type":"stream"},{"name":"stdout","text":"Accuracy of the network on the 10000 test images: 98.68 %\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Tensorboard","metadata":{"id":"6TJjsQKk1PAS"}},{"cell_type":"code","source":"tb.flush()\ntb.close()\n%load_ext tensorboard\n%tensorboard --logdir=runs/LeNET","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}